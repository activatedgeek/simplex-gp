{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0ffdb161abba9b4c6ed90ea70f14a998c2b70ba8faeee50224e9918737cdc1ef1",
   "display_name": "Python 3.9.2 64-bit ('bilateral-gp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gpytorch as gp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else None\n",
    "\n",
    "sns.set(font_scale=2.0, style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gp.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        likelihood = gp.likelihoods.GaussianLikelihood()\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gp.means.ZeroMean()\n",
    "        self.covar_module = gp.kernels.ScaleKernel(gp.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gp.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('snelson.csv')\n",
    "train_x = torch.from_numpy(df.x.values[:, np.newaxis]).float().to(device)[:10]\n",
    "train_y = torch.from_numpy(df.y.values).float().to(device)[:10]\n",
    "\n",
    "train_x = (train_x - train_x.mean(dim=0, keepdim=True)) / (train_x.std(dim=0, keepdim=True) + 1e-6)\n",
    "train_y = (train_y - train_y.mean(dim=0, keepdim=True)) / (train_y.std(dim=0, keepdim=True) + 1e-6)\n",
    "\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExactGPModel(train_x, train_y).to(device)\n",
    "with torch.no_grad():\n",
    "    all_x = torch.linspace(-3., 3., 200).to(device).unsqueeze(-1)\n",
    "    prior = model.forward(all_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, model, mll, optim):\n",
    "    model.train()\n",
    "\n",
    "    optim.zero_grad()\n",
    "\n",
    "    output = model(x)\n",
    "    loss = -mll(output, y)\n",
    "\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    return { 'train/mll': -loss.detach().item() }\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=.1)\n",
    "mll = gp.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "for i in tqdm(range(50)):\n",
    "    print(train(train_x, train_y, model, mll, optim))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    posterior = model(all_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fns(x, f):\n",
    "    y = torch.cat([x.expand(-1, 3).permute(1, 0).unsqueeze(-1), f.unsqueeze(-1)], axis=-1)\n",
    "\n",
    "    viz_data = []\n",
    "    for i in range(3):\n",
    "        for idx in range(200):\n",
    "            viz_data.append({ 'id': i, 'x': y[i][idx][0].item(), 'y': y[i][idx][1].item() })\n",
    "    viz_data = pd.DataFrame(viz_data)\n",
    "    fig, ax = plt.subplots(figsize=(11,7))\n",
    "    sns.lineplot(ax=ax, data=viz_data, x='x', y='y', hue='id', legend=False, \n",
    "                 palette=sns.color_palette('Set1', 3), alpha=.7)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "fig_prior, ax_prior = plot_fns(all_x, prior.sample(torch.Size([3])))\n",
    "ax_prior.plot(all_x.cpu().numpy().flatten(), prior.mean.cpu().numpy(), linestyle=(0, (10,5)),\n",
    "              color='black', alpha=.6, linewidth=3)\n",
    "with torch.no_grad():\n",
    "    ax_prior.fill_between(all_x.cpu().numpy().flatten(),\n",
    "                        prior.mean.cpu().numpy() - 2. * prior.variance.sqrt().cpu().numpy(),\n",
    "                        prior.mean.cpu().numpy() + 2. * prior.variance.sqrt().cpu().numpy(),\n",
    "                        color='grey', alpha=.15)\n",
    "ax_prior.set_title('Prior')\n",
    "ax_prior.set_yticks(np.arange(-2, 2.1))\n",
    "ax_prior.set_ylim([-2.5,2.5])\n",
    "\n",
    "fig_post, ax_post = plot_fns(all_x, posterior.sample(torch.Size([3])))\n",
    "ax_post.plot(all_x.cpu().numpy().flatten(), posterior.mean.cpu().numpy(), linestyle=(0, (10,5)),\n",
    "             color='black', alpha=.6, linewidth=3)\n",
    "with torch.no_grad():\n",
    "    ax_post.fill_between(all_x.cpu().numpy().flatten(),\n",
    "                        posterior.mean.cpu().numpy() - 2. * posterior.variance.sqrt().cpu().numpy(),\n",
    "                        posterior.mean.cpu().numpy() + 2. * posterior.variance.sqrt().cpu().numpy(),\n",
    "                        color='grey', alpha=.15)\n",
    "sns.scatterplot(ax=ax_post, x=train_x.squeeze(-1).cpu().numpy(), y=train_y.cpu().numpy(),\n",
    "                color='red', s=100, edgecolor='black', linewidth=1)\n",
    "ax_post.set_title('Posterior')\n",
    "ax_post.set_yticks(np.arange(-2, 2.1))\n",
    "ax_post.set_ylim([-2.5,2.5]);\n",
    "\n",
    "fig_prior.savefig('prior.pdf', bbox_inches='tight')\n",
    "fig_post.savefig('post.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}