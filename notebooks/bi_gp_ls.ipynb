{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "if os.path.abspath('..') not in sys.path:\n",
    "    sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import gpytorch as gp\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bi_gp.bilateral_kernel import BilateralKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gp.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        likelihood = gp.likelihoods.GaussianLikelihood()\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        # self.mean_module = gp.means.ConstantMean()\n",
    "        # self.covar_module = gp.kernels.ScaleKernel(gp.kernels.RBFKernel(ard_num_dims=train_x.size(-1)))\n",
    "        self.mean_module = gp.means.ZeroMean()\n",
    "        self.covar_module = gp.kernels.RBFKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gp.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "      \n",
    "class BilateralGPModel(gp.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y):\n",
    "        likelihood = gp.likelihoods.GaussianLikelihood()\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        # self.mean_module = gp.means.ConstantMean()\n",
    "        # self.covar_module = gp.kernels.ScaleKernel(BilateralKernel(ard_num_dims=train_x.size(-1)))\n",
    "        self.mean_module = gp.means.ZeroMean()\n",
    "        self.covar_module = BilateralKernel()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gp.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "class SKIPGPModel(gp.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, grid_size):\n",
    "        likelihood = gp.likelihoods.GaussianLikelihood()\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        \n",
    "#         self.mean_module = gp.means.ConstantMean()\n",
    "#         self.base_covar_module = gp.kernels.RBFKernel()\n",
    "#         self.covar_module = gp.kernels.ProductStructureKernel(\n",
    "#             gp.kernels.ScaleKernel(\n",
    "#                 gp.kernels.GridInterpolationKernel(self.base_covar_module, grid_size=grid_size, num_dims=1)\n",
    "#             ), num_dims=train_x.size(-1)\n",
    "#         )\n",
    "\n",
    "        self.mean_module = gp.means.ZeroMean()\n",
    "        self.base_covar_module = gp.kernels.RBFKernel()\n",
    "        self.covar_module = gp.kernels.ProductStructureKernel(\n",
    "            gp.kernels.GridInterpolationKernel(self.base_covar_module, grid_size=grid_size, num_dims=1),\n",
    "            num_dims=train_x.size(-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gp.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, model, mll, optim):\n",
    "    model.train()\n",
    "\n",
    "    optim.zero_grad()\n",
    "\n",
    "    output = model(x)\n",
    "\n",
    "    loss = -mll(output, y)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optim.step()\n",
    "\n",
    "    return { 'train/ll': -loss.detach().item() }\n",
    "\n",
    "\n",
    "def test(x, y, model, lanc_iter=100, pre_size=0):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "#        gp.settings.max_preconditioner_size(pre_size), \\\n",
    "#        gp.settings.max_root_decomposition_size(lanc_iter), \\\n",
    "#        gp.settings.fast_pred_var():\n",
    "        preds = model(x)\n",
    "\n",
    "        pred_y = model.likelihood(model(x))\n",
    "        rmse = (pred_y.mean - y).pow(2).mean(0).sqrt()\n",
    "\n",
    "    return { 'test/rmse': rmse.item() }\n",
    "\n",
    "\n",
    "def train_util(model, x, y, lr=0.1, epochs=100):\n",
    "    mll = gp.mlls.ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for _ in tqdm(range(epochs), leave=False):\n",
    "        train_dict = train(x, y, model, mll, optim)\n",
    "    \n",
    "    return train_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy 4-D GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2000\n",
    "d = 4\n",
    "x = 2. * torch.rand(n, d) - 1.\n",
    "\n",
    "with torch.no_grad():\n",
    "  covar_module = gp.kernels.ScaleKernel(gp.kernels.RBFKernel())\n",
    "  params = covar_module.state_dict()\n",
    "  params['raw_outputscale'] = torch.tensor(1.0).log()\n",
    "  params['base_kernel.raw_lengthscale'] = torch.Tensor([[1.5]]).log()\n",
    "  covar_module.load_state_dict(params)\n",
    "\n",
    "  covar = gp.distributions.MultivariateNormal(torch.zeros(n), covariance_matrix=covar_module(x))\n",
    "\n",
    "rperm = torch.randperm(n)[:n//2]\n",
    "train_x = x[rperm]\n",
    "train_y = (covar.sample() + 0.1 * torch.randn(x.size(0)))[rperm]\n",
    "\n",
    "#   sample_x = x.squeeze(-1).unsqueeze(0).expand(5, -1).numpy()\n",
    "#   sample_y = covar.sample(torch.Size([5])).numpy()\n",
    "#   label = np.repeat(np.array([['a', 'b', 'c', 'd', 'e']]).T, n, axis=1)\n",
    "#   plot_data = {\n",
    "#     'x': sample_x.flatten().tolist(),\n",
    "#     'y': sample_y.flatten().tolist(),\n",
    "#     'id': label.flatten()\n",
    "#   }\n",
    "\n",
    "# alt.Chart(pd.DataFrame(plot_data)).mark_line().encode(x='x', y='y', color='id') +\\\n",
    "# alt.Chart(pd.DataFrame({ 'x': train_x.squeeze(-1).numpy(), 'y': train_y.numpy() })).mark_circle().encode(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "  egp = ExactGPModel(train_x, train_y).float()\n",
    "\n",
    "  train_dict = train_util(egp, train_x, train_y)\n",
    "  \n",
    "  for name, p in egp.named_parameters():\n",
    "    results[name].append(p)\n",
    "  results['kind'].append('Exact GP')\n",
    "  for k, v in train_dict.items():\n",
    "    results[k].append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "  bigp = BilateralGPModel(train_x, train_y).float()\n",
    "\n",
    "  with gp.settings.max_root_decomposition_size(50):\n",
    "    train_dict = train_util(bigp, train_x, train_y)\n",
    "  \n",
    "  for name, p in bigp.named_parameters():\n",
    "    results[name].append(p)\n",
    "  results['kind'].append('Bilateral GP')\n",
    "    \n",
    "  for k, v in train_dict.items():\n",
    "    results[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "  skipgp = SKIPGPModel(train_x, train_y, 100).float()\n",
    "\n",
    "  with gp.settings.max_root_decomposition_size(50):\n",
    "    train_dict = train_util(skipgp, train_x, train_y)\n",
    "  \n",
    "  for name, p in skipgp.named_parameters():\n",
    "    results[name].append(p)\n",
    "  results['kind'].append('SKIP-GP')\n",
    "    \n",
    "  for k, v in train_dict.items():\n",
    "    results[k].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  'obs_noise': [v.exp().item() for v in results['likelihood.noise_covar.raw_noise']],\n",
    "  'ls': [v.exp().item() for v in results['covar_module.raw_lengthscale']] + [v.exp().item() for v in results['base_covar_module.raw_lengthscale']],\n",
    "  'train/ll': results['train/ll'],\n",
    "  'kind': results['kind'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bars = alt.Chart(pd.DataFrame(data)).mark_errorbar(extent='stdev').encode(\n",
    "  x=alt.X('obs_noise:Q', scale=alt.Scale(zero=False)),\n",
    "  y=alt.Y('kind:N')\n",
    ")\n",
    "\n",
    "points = alt.Chart(pd.DataFrame(data)).mark_point(filled=True, color='black').encode(\n",
    "  x=alt.X('obs_noise:Q', aggregate='mean'),\n",
    "  y=alt.Y('kind:N'),\n",
    ")\n",
    "\n",
    "(error_bars + points).properties(width=800,height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bars = alt.Chart(pd.DataFrame(data)).mark_errorbar(extent='stdev').encode(\n",
    "  x=alt.X('ls:Q', scale=alt.Scale(zero=False)),\n",
    "  y=alt.Y('kind:N')\n",
    ")\n",
    "\n",
    "points = alt.Chart(pd.DataFrame(data)).mark_point(filled=True, color='black').encode(\n",
    "  x=alt.X('ls:Q', aggregate='mean'),\n",
    "  y=alt.Y('kind:N'),\n",
    ")\n",
    "\n",
    "(error_bars + points).properties(width=800,height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bars = alt.Chart(pd.DataFrame(data)).mark_errorbar(extent='stdev').encode(\n",
    "  x=alt.X('train/ll:Q', scale=alt.Scale(zero=False)),\n",
    "  y=alt.Y('kind:N')\n",
    ")\n",
    "\n",
    "points = alt.Chart(pd.DataFrame(data)).mark_point(filled=True, color='black').encode(\n",
    "  x=alt.X('train/ll:Q', aggregate='mean'),\n",
    "  y=alt.Y('kind:N'),\n",
    ")\n",
    "\n",
    "(error_bars + points).properties(width=800,height=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
